{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source_url": "https://www.youtube.com/watch?v=sVcwVQRHIc8", "type": "chunk", "doc_id": "1aae35a2-a475-4f19-8e8d-559d3093c329", "original_doc_id": "2934a702-1b8a-4c62-a8dc-5dad86053b47"}, "page_content": "approach that's worth mentioning here uh because it's pretty interesting um and let's walk through the code so there's actually nice Library called rouille which makes it very easy to play with Co bear um she's pip install it here I've already done that and we can use one of their pre-train models to mediate this process so I'm basically following their documentation this is kind of what they recommended um so I'm running this now hopefully this runs somewhat quickly I'm not sure I I previously have loaded this model so hopefully it won't take too long and yeah you can see it's pretty quick uh I'm on a Mac M2 with 32 gigs um so just as like a context in terms of my my system um this is from their documentation we're just grabbing a Wikipedia page this is getting a full document on Miyazaki so that's cool we're going to grab that now this is just from their docs this is basically how we create an index so we provide the you know some index name the collection um the max document length and yeah you should look at their documentation for these flags these are just the defaults so I'm going to create my index um so I get some logging here so it it's working under the hood um and by the way I actually have their documentation open so you can kind of follow along um so um let's see yeah right about here so you can kind of follow this indexing process to create an index you need to load a train uh a trained model this can be either your own pre-train model or one of ours from The Hub um and this is kind of the process we're doing right now create index is just a few lines of code and this is exactly what we're doing um so this is the you know my documents and this is the indexing step that we just we just kind of walk through and it looks like it's done um so you get a bunch of logging here that's fine um now let's actually see if this works so we're going to run drag search what an emotion Studio did Miaki found set our K parameter and we get some results okay so it's running and cool we get some documents out so you know it seems to work now what's nice is you can run this within lighting chain as a liting chain retriever so that basically wraps this as a lighting chain Retriever and then you can use it freely as a retriever within Lang chain it works with all the other different LMS and all the other components like rankers and so forth that we talk through so you can use this directly as a retriever let's try this out and boom nice and fast um and we get our documents again this is a super simple test example you should run this maybe on more complex cases but it's pretty pretty easy spin up it's a really interesting alternative indexing approach um using again like we talked through um a very different algorithm for computing do similarity that may work better I think an interesting regime to consider this would be longer documents so if you want like longer um yeah if if you basically want kind of long context embedding I think you should look into for example the uh Max token limits for this approach because it partitions the document into into each token um I would be curious to dig into kind of what the overall context limits are for this approach of coar but it's really interesting to consider and it reports very strong performance so again I encourage you to play with it and this is just kind of an intro to how to get set up and to start experimenting with it really quickly thanks hi this is Lance from Lang chain I'm going to be talking about using langra to build a diverse and sophisticated rag flows so just to set the stage the basic rag flow you can see here starts with a question retrieval of relevant documents from an index which are passed into the context window of an llm for generation of an answer ground in your documents that's kind of the basic outline and we can see it's like a very linear path um in practice though you often encounter a few different types of questions like when do we actually want to retrieve based upon the context of the question um are the retrieve documents actually good or not and if they're not good should we discard them and then how do we loot back and retry retrieval with for example and improved question so these types of questions motivate an idea of active rag which is a process where an llm actually decides when and where to retrieve based upon like existing retrievals or existing Generations now when you think about this there's a few different levels of control that you have over an llm in a rag application the base case like we saw with our chain is just use an llm to choose a single steps output so for example in traditional rag you feed it documents and it decides to generation so it's just kind of one step now a lot of rag workflows will use the idea of routing so like given a question should I route it to a vector store or a graph DB um and we have seen this quite a bit now this newer idea that I want to introduce is how do we build more sophisticated logical flows um in a rag pipeline um that you let the llm choose between different steps but specify all the transitions that are available and this is known as we call a state machine now there's a few different architectures that have emerged uh to build different types of rag chains and of course chains are traditionally used just for like very basic rag but this notion of State machine is a bit newer and Lang graph which we recently released provides a really nice way to build State machines for Rag and for other things and the general idea here is that you can lay out more diverse and complicated rag flows and then Implement them as graphs and it kind of motivates this more broad idea of of like flow engineering and thinking through the actual like workflow that you want and then implementing it um and we're gonna actually do that right now so I'm GNA Pi a recent paper called CAG corrective rag which is really a nice method um for active rag that incorporates a few different ideas um so first you retrieve documents and then you grade them now if at least one document exceeds the threshold for relevance you go to generation you generate your answer um and it does this knowledge refinement stage after that but let's not worry about that for right now it's kind of not essential for understanding the basic flow here so again you do a grade for relevance for every document if any is relevant you generate now if they're all ambiguous or incorrect based upon your grader you retrieve from an external Source they use web search and then they pass that as their context for answer generation so it's a really neat workflow where you're doing retrieval just like with basic rag but then you're reasoning about the documents if they're relevant go ahead and at least one is relevant go ahead and generate if they're not retrieve from alternative source and then pack that into the context and generate your answer so let's see how we would implement this as a estate machine using Lang graph um we'll make a few simplifications um we're going to first decide if any documents are relevant we'll go ahead and do the the web search um to supplement the output so that's just like kind of one minor modification um we'll use tab search for web search um we use Query writing to optimize the search for uh to optimize the web search but it follows a lot of the the intuitions of the main paper uh small note here we set the Tav API key and another small mode I've already set my lsmith API key um with which we'll see is useful a bit later for observing the resulting traces now I'm going to index three blog posts that I like um I'm going to use chroma DB I'm G use open ey embeddings I'm going to run this right now this will create a vector store for me from these three blog posts and then what I'm going to do is Define State now this is kind of the core object that going to be passed around my graph that I'm going to modify and right here is where I Define it and the key point to note right now is it's just a dictionary and it can contain things that are relevant for rag like question documents generation and we'll see how we update that in in in a little bit but the first thing to note is we Define our state and this is what's going to be modified in every Noe of our graph now here's really the Crux of it and this is the thing I want to zoom in on a little bit um so when you kind of move from just thinking about promps to thinking about overall flows it it's like kind of a fun and interesting exercise I kind of think about this as it's been mentioned on Twitter a little bit more like flow engineering so let's think through what was actually done in the paper and what modifications to our state are going to happen in each stage so we start with a question you can see that on the far left and this kind of state is represent as a dictionary like we have we start with a question we perform retrieval from our Vector store which we just created that's going to give us documents so that's one node we made an an adjustment to our state by adding documents that's step one now we have a second node where we're going to grade the documents and in this node we might filter some out so we are making a modification to state which is why it's a node so we're going to have a greater then we're going to have what we're going to call a conditional Edge so we saw we went from question to retrieval retrieval always goes to grading and now we have a decision if any document is irrelevant we're going to go ahead and do web search to supplement and if they're all relevant will go to generation it's a minor kind of a minor kind of logical uh decision ision that we're going to make um if any are not relevant we'll transform the query and we'll do web search and we'll use that for Generation so that's really it and that's how we can kind of think about our flow and how our States can be modified throughout this flow now all we then need to do and I I kind of found spending 10 minutes thinking carefully through your flow engineering is really valuable because from here it's really implementation details um and it's pretty easy as you'll see so basically I'm going to run this code block but then we can like walk through some of it I won't show you everything so it'll get a little bit boring but really all we're doing is we're finding functions for every node that take in the state and modify in some way that's all it's going on so think about retrieval we run retrieval we take in state remember it's a dict we get our state dick like this we extract one keyy question from our dick we pass that to a retriever we get documents and we write back out State now with documents key added that's all generate going to be similar we take in state now we have our question and documents we pull in a prompt we Define an llm we do minor post processing on documents we set up a chain for retrieval uh or sorry for Generation which is just going to be take our prompt pump Plum that to an llm partially output a string and we run it right here invoking our documents in our question to get our answer we write that back to State that's it and you can kind of follow here for every node we just Define a function that performs the state modification that we want to do on that node grading documents is going to be the same um in this case I do a little thing extra here because I actually Define a identic data model for my grader so that the output of that particular grading chain is a binary yes or no you can look at the code make sure it's all shared um and that just makes sure that our output is is very deterministic so that we then can down here perform logical filtering so what you can see here is um we Define this search value no and we iterate through our documents we grade them if any document uh is graded as not relevant we flag this search thing to yes that means we're going to perform web search we then add that to our state dict at the end so run web search now that value is true that's it and you can kind of see we go through some other nodes here there's web search node um now here is where our one conditional Edge we Define right here this is where where we decide to generate or not based on that search key so we again get our state let's extract the various values so we have this search value now if search is yes we return the next no that we want to go to so in this case it'll be transform query which will then go to web search else we go to generate so what we can see is we laid out our graph which you can kind of see up here and now we Define functions for all those nodes as well as the conditional Edge and now we scroll down all we have to do is just lay that out here again as our flow and this is kind of what you might think of as like kind of flow engineering where you're just laying out the graph as you drew it where we have set our entry point as retrieve we're adding an edge between retrieve and grade documents so we went retrieval grade documents we add our conditional Edge depending on the grade either transform the query go to web search or just go to generate we create an edge between transform the query and web search then web search to generate and then we also have an edge generate to end and that's our whole graph that's it so we can just run this and now I'm going to ask a question so let's just say um how does agent memory work for example let's just try that and what this is going to do is going to print out what's going on as we run through this graph so um first we going to see output from retrieve this is going to be all of our documents that we retrieved so that's that's fine this just from our our retriever then you can see that we're doing a relevance check across our documents and this is kind of interesting right you can see we grading them here one is grade as not relevant um and okay you can see the documents are now filtered because we removed the one that's not relevant and because one is not relevant we decide okay we're going to just transform the query and run web search and um you can see after query transformation we rewrite the question slightly we then run web search um and you can see from web search it searched from some additional sources um which you can actually see here it's appended as a so here it is so here it's a new document appended from web search which is from memory knowledge requirements so it it basically looked up some AI architecture related to memory uh web results so that's fine that's exactly what we want to do and then um we generate a response so that's great and this is just showing you everything in kind of gory detail but I'm going to show you one other thing that's that's really nice about this if I go to lsmith I have my AP I ke set so all my Generations are just logged to to lsmith and I can see my Lang graph run here now what's really cool is this shows me all of my nodes so remember we had retrieve grade we evaluated the grade because one was irrelevant we then went ahead and transformed the query we did a web search we pended that to our context you can see all those steps are laid out here in fact you can even look at every single uh grader and its output I will move this up slightly um so you can see the the different scores for grades okay so this particular retrieval was graded as as not relevant so that's fine that that can happen in some cases and because of that um we did a query transformation so we modified the question slightly how does memory how does the memory system an artificial agents function so it's just a minor rephrasing of the question we did this Tav web search this is where it queried from this particular blog post from medium so it's like a sing web query we can like sanity check it and then what's need is we can go to our generate step look at open Ai and here's our full prompt how does the memory system in our official agents function and then here's all of our documents so this is the this is the web search as well as we still have the Rel chunks that were retrieved from our blog posts um and then here's our answer so that's really it you can see how um really moving from the notion of just like I'll actually go back to the original um moving from uh I will try to open this up a little bit um yeah I can see my face still um the transition from laying out simple chains to flows is a really interesting and helpful way of thinking about why graphs are really interesting because you can encode more sophisticated logical reasoning workflows but in a very like clean and well-engineered way where you can specify all the transitions that you actually want to have executed um and I actually find this way of thinking and building kind of logical uh like workflows really intuitive um we have a blog post coming out uh tomorrow that discusses both implementing self rag as well as C rag for two different active rag approaches using using uh this idea of of State machines and Lang graph um so I encourage you to play with it uh I found it really uh intuitive to work with um I also found uh inspection of traces to be quite intuitive using Lang graph because every node is enumerated pretty clearly for you which is not always the case when you're using other types of of more complex reasoning approaches for example like agents so in any case um I hope this was helpful and I definitely encourage you to check out um kind of this notion of like flow engineering using Lang graph and in the context of rag it can be really powerful hopefully as you've seen here thank you hey this is Lance from Lang chain I want to talk to a recent paper that I saw called adaptive rag which brings together some interesting ideas that have kind of been covered in other videos but this actually ties them all together in kind of a fun way so the the two big ideas to talk about here are one of query analysis so we've actually done kind of a whole rag from scratch series that walks through each of these things in detail but this is a very nice example of how this comes together um with some other ideas we've been talking about so query analysis is typically the process of taking an input question and modifying in some way uh to better optimize retrieval there's a bunch of different methods for this it could be decomposing it into sub questions it could be using some clever techniques like stepb back prompting um but that's kind of like the first stage of query analysis then typically you can do routing so you route a question to one of multiple potential sources it could be one or two different Vector stores it could be relational DB versus Vector store it could be web search it could just be like an llm fallback right so this is like one kind of big idea query analysis right it's kind of like the front end of your rag pipeline it's taking your question it's modifying it in some way it's sending it to the right place be it a web search be it a vector store be it a relational DB so that's kind of topic one now topic two is something that's been brought up in a few other videos um of what I kind of call Flow engineering or adaptive rag which is the idea of doing tests in your rag pipeline or in your rag inference flow uh to do things like check relevance documents um check whether or not the answer contains hallucinations so this recent blog post from Hamil Hussein actually covers evaluation in in some really nice detail and one of the things he highlighted explicitly is actually this topic so he talks about unit tests and in particular he says something really interesting here he", "type": "Document"}}