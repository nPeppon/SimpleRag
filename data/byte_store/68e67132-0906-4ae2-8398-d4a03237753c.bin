{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source_url": "https://www.youtube.com/watch?v=sVcwVQRHIc8", "type": "chunk", "doc_id": "68e67132-0906-4ae2-8398-d4a03237753c", "original_doc_id": "2934a702-1b8a-4c62-a8dc-5dad86053b47"}, "page_content": "different Vector stores it could be relational DB versus Vector store it could be web search it could just be like an llm fallback right so this is like one kind of big idea query analysis right it's kind of like the front end of your rag pipeline it's taking your question it's modifying it in some way it's sending it to the right place be it a web search be it a vector store be it a relational DB so that's kind of topic one now topic two is something that's been brought up in a few other videos um of what I kind of call Flow engineering or adaptive rag which is the idea of doing tests in your rag pipeline or in your rag inference flow uh to do things like check relevance documents um check whether or not the answer contains hallucinations so this recent blog post from Hamil Hussein actually covers evaluation in in some really nice detail and one of the things he highlighted explicitly is actually this topic so he talks about unit tests and in particular he says something really interesting here he says you know unlike typical unit tests you want to organize these assertions in places Beyond typical unit testing such as data cleaning and here's the key Point automatic retries during model inference that's the key thing I want to like draw your attention to to it's a really nice approach we've talked about some other papers that do that like corrective rag self rag but it's also cool to see it here and kind of encapsulated in this way the main idea is that you're using kind of unit tests in your flow to make Corrections like if your retrieval is bad you can correct from that if your generation has hallucinations you can correct from that so I'm going to kind of draw out like a cartoon diagram of what we're going to do here and you can kind of see it here we're starting with a question we talked about query analysis we're going to take our question and we're going to decide where it needs to go and for this particular toy example I'm going to say either send it to a vector store send it to web search or just have the llm answer it right so that's like kind of my fallback Behavior then we're going to bring in that idea of kind of online flow engineering or unit testing where I'm going to have my retrieval either from the VOR store or web search I'm then going to ask is this actually relevant to the question if it isn't I'm actually going to kick back to web sech so this is a little bit more relevant in the case if I've routed to to the vector store done retrieval documents aren't relevant I'll have a fallback mechanism um then I'm going to generate I check for hallucinations in my generation and then I check for um for whether or not the the generation actually answers the question then I return my answer so again we're tying together two ideas one is query analysis like basically taking a question routing it to the right place modifying it as needed and then kind of online unit testing and iterative flow feedback so to do this I've actually heard a lot of people talk online about command r a new model release from gooh here it has some pretty nice properties that I was kind of reading about recently so one it has nice support for Tool use and it does support query writing in the context of tool use uh so this all rolls up in really nice capabilities for routing it's kind of one now two it's small it's 35 billion parameter uh it's actually open weight so you can actually run this locally and I've tried that we can we can talk about that later uh so and it's also fast served via the API so it's kind of a small model and it's well tuned for rag so I heard a lot of people talking about using coher for Rag and it has a large context 120,000 tokens so this like a nice combination of properties it supports to and routing it's small and fast so it's like quick for grading and it's well tuned for rag so it's actually a really nice fit for this particular workflow where I want to do query analysis and routing and I want to do kind of online checking uh and rag so kind of there you go now let's just get to the coding bit so I have a notebook kind of like usual I've done a few pip installs you can see it's nothing exotic I'm bringing Lang chain coh here I set my coher API key now I'm just going to set this Lang chain project within lsmith so all my traces for this go to that project and I have enabled tracing so I'm using Langs Smith here so we're going to walk through this flow and let's do the first thing let's just build a vector store so I'm going to build a vector store using coherent beddings with chroma open source Vector DB runs locally from three different web pages on blog post that I like so it pertains to agents prompt engineering and adversarial attacks so now I have a retriever I can run retriever invoke and I can ask a question about you know agent memory agent memory and there we go so we get documents back so there we go we have a retriever now now here's where I'm going to bring in coh here I also want a router so you look at our flow the first step is this routing stage right so what I'm going to do is I'm guess we going to find two tools a web search tool and a vector store tool okay in my Preamble is just going to say you're an expert routing user questions to Vector store web search now here's the key I tell it what the vector store has so again my index my Vector store has agents prompt engineering adial tax I just repeat that here agents prompt adversarial tax so it knows what's in the vector store um so use it for questions on these topics otherwise use web search so that's it I use command R here now I'm going to bind these tools to the model and attach the Preamble and I have a structured LM router so let's give it a let's give this a few tests just to like kind of sandbox this a little bit so I can inval here's my chain I have a router prompt I pass that to the structured LM router which I defined right here and um let's ask a few different questions like who will the Bears draft in the NFL draft with types of agent memory and Hi how are you so I'm going to kick that off and you can see you know it does web search it does it goes to Vector store and then actually returns this false so that's kind of interesting um this is actually just saying if it does not use either tool so for that particular query web search or the vector store was inappropriate it'll just say hey I didn't call one of those tools so that's interesting we'll use that later so that's my router tool now the second thing is my grader and here's where I want to show you something really nice that is generally useful uh for many different problems you might encounter so here's what I'm doing I'm defining a data model uh for My Grade so basically grade documents it's going to have this is a pantic object it is just basically a binary score here um field specified here uh documents are relevant to the question yes no I have a preamble your grer assessing relevance of retrieve documents to a user question um blah blah blah so you know and then basically give it a b score yes no I'm using command R but here's the catch I'm using this wi structured outputs thing and I'm passing my grade documents uh data model to that that so this is the key thing we can test this right now as well it's going to return an object based on the schema I give it which is extremely useful for all sorts of use cases and let's actually Zoom back up so we're actually right here so this greater stage right I want to constrain the output to yes no I don't want any preambles I want anything because the logic I'm going to build in this graph is going to require a yes no binary response from this particular Edge in our graph so that's why this greater tool is really useful and I'm asking like a mock question types of agent memory I do a retriever I do a retrieval from our Vector store I get the tuck and I test it um I invoke our greater retrieval grater chain with the question the doc text and it's relevant as we would expect so that's good but again let's just kind of look at that a little bit more closely what's actually happening under the hood here here's the pantic object we passed here's the document in question I'm providing basically it's converting this object into coher function schema it's binding that to the llm we pass in the document question it returns an object basic a Json string per our pantic schema that's it and then it's just going to like parse that into a pantic object which we get at the end of the day so that's what's happening under the hood with this with structured output thing but it's extremely useful and you'll see we're going to use that a few different places um um because we want to ensure that in our in our flow here we have three different grading steps and each time we want to constrain the output to yes no we're going to use that structured output more than once um this is just my generation so this is good Old Rag let's just make sure that works um I'm using rag chain typical rag prompt again I'm using cohere for rag pretty easy and yeah so the rag piece works that's totally fine nothing to it crazy there um I'm going to find this llm fallback so this is basically if you saw a router chain if it doesn't use a tool I want to fall back and just fall back to the llm so I'm going to kind of build that as a little chain here so okay this is just a fallback I have my Preamble just you're you're an assistant answer the question based upon your internal knowledge so again that fallback behavior is what we have here so what we've done already is we defined our router piece we've defined our our basic retrieval our Vector store we already have here um we've defined our first logic or like grade check and we defined our fallback and we're just kind of roll through the parts of our graph and Define each piece um so I'm going to have two other graders and they're going to use the same thing we just talked about slightly different data model I mean same output but actually just slightly different uh prompt um and you know descript destion this in this case is the aners grounded the facts yes no this is my hallucination grater uh and then I have an answer grader as well and I've also run a test on each one and you can see I'm getting binary this this these objects out have a binary score so this a pantic object with a binary score uh and that's exactly what we want cool and I have a Search tool so that's really nice we've actually gone through and we've kind of laid out I have like a router I've tested it we have a vector story tested we've tested each of our graders here we've also tested generation of just doing rag so we have a bunch of pieces built here we have a fallback piece we have web search now the question is how do I Stitch these together into this kind of flow and for that I I like to use Lang graph we'll talk a little about Lang graph versus agents a bit later but I want to show you why this is really easy to do using Lang graph so what's kind of nice is I've kind of laid out all my logic here we've tested individually and now all I'm going to do is I'm going to first lay out uh the parts of my graph so what you're going to notice here is first there's a graph state so this state represents kind of the key parts of the graph or the key kind of objects within the graph that we're going to be modifying so this is basically a graph centered around rag we're going to have question generation and documents that's really kind of the main things we're going to be working with in our graph so then you're going to see something that's pretty intuitive I think what you're going to see is we're going to basically walk through this flow and for each of these little circles we're just going to find a function and these uh little squares or these these you can think about every Circle as a node and every kind of diamond here as as an edge or conditional Edge so that's actually what we're going to do right now we're going to lay out all of our nodes and edges and each one of them are just going to be a function and you're going to see how we do that right now so I'm going to go down here I def find my graph state so this is what's going to be kind of modified and propagated throughout my graph now all I'm going to do is I'm just going to find a function uh for each of those nodes so let me kind of go side by side and show you the diagram and then like kind of show the nodes next to it so here's the diagram so we have uh a retrieve node so that kind of represents our Vector store we have a fallback node that's this piece we have a generate node so that's basically going to do our rag you can see there we have a grade documents node kind of right here um and we have a web search node so that's right here cool now here's where we're actually to find the edges so you can see our edges are the pieces of the graph that are kind of making different decisions so this route question Edge basic conditional Edge is basically going to take an input question and decide where it needs to go and that's all we're doing down here it kind of follows what we did up at the top where we tested this individually so recall we basically just invoke that question router returns our source now remember if tool calls were not in the source we do our fall back so we show actually showed that all the way up here remember this if tool calls is not in the response this thing will just be false so that means we didn't either we didn't call web search and we didn't call uh our retriever tool so then we're just going to fall back um yep right here and this is just like uh you know a catch just in case a tool could make a decision but most interestingly here's where we choose a data source basically so um this is the output of our tool call we're just going to fish out the name of the tool so that's data source and then here we go if the data source is web search I'm returning web search as basically the next node to go to um otherwise if it's Vector store we return Vector store as the next node to go to so what's this search thing well remember we right up here Define this node web search that's it we're just going to go to that node um what's this Vector store um you'll see below how we can kind of tie these strings that we returned from the conditional Edge to the node we want to go to that's really it um same kind of thing here decide to generate that's going to roll in these two conditional edges into one um and basically it's going to do if there's no documents so basic basically if we filtered out all of our documents from this first test here um then what we're going to do is we've decided all documents are not relevant to the question and we're going to kick back to web search exactly as we show here so that's this piece um otherwise we're going to go to generate so that's this piece so again in these conditional edges you're basically implementing the logic that you see in our diagram right here that's all that's going on um and again this is just implementing the final two checks uh for hallucinations and and answer relevance um and um yep so here's our hallucination grader we then extract the grade if the if basically there are hallucinations um oh sorry in this case the grade actually yes means that the answer is grounded so we say answer is actually grounded and then we go to the next step we go to the next test that's all this is doing it's just basically wrapping this logic that we're implementing here in our graph so that's all that's going on and let's go ahead and Define all those things so nice we have all that um now we can actually go down a little bit and we can pull um this is actually where we stitch together everything so all it's happening here is you see we defined all these functions up here we just add them as nodes in our graph here and then we build our graph here basically by by basically laying out the flow or the connectivity between our nodes and edges so you know you can look at this notebook to kind of study in a bit of detail what's going on but frankly what I like to do here typically just draw out a graph kind of like we did up here and then Implement uh the Lo logical flow here in your graph as nodes and edges just like we're doing here that's all that's happening uh so again we have like our entry point is the router um this is like the output is this is basically directing like here's what the router is outputting and here's the next node to go to so that's it um and then for each node we're kind of applying like we're saying like what's what's the flow so web search goes to generate after um and retrieve goes to grade documents grade documents um kind of is is like is a conditional Edge um depending on the results we either do web search or generate and then our second one we go from generate to uh basically this grade uh generation versus documents in question based on the output of that we either have hallucinations we regenerate uh we found that the answer is not useful we kick back to web search or we end um finally we have that llm fallback and that's also if we go to the fallback we end so what you're seeing here is actually the the logic flow we're laying out in this graph matches the diagram that we laid out up top I'm just going to copy these over and I'll actually go then back to the diagram and and kind of underscore that a little bit more so here is the flow we've laid out again here is our diagram and you can kind of look at them side by side and see how they basically match up so here's kind of our flow diagram going from basically query analysis that's this thing this route question and you can see web search Vector store LM fallback LM fallback web search vector store so those are like the three options that can come out of this conditional Edge and then here's where we connect so if we go to web search then basically we next go to generate so that's kind of this whole flow um now if we go to retrieve um then we're going to grade so that's it um and you know it follows kind of as you can see here that's really it uh so it's just nice to draw the these diagrams out first and then it's pretty quick to implement each node and each Edge just as a function and then stitch them together in a graph just like I show here and of course we'll make sure this code's publ so you can use it as a reference um so there we go now let's try a few a few different test questions so like what player the Bears to draft and NFL draft right let's have a look at that and they should print everything it's doing as we go so okay this is important route question it just decides to route to web search that's good it doesn't go to our Vector store this is a current event not related to our Vector store at all it goes to web search um and then it goes to generate so", "type": "Document"}}