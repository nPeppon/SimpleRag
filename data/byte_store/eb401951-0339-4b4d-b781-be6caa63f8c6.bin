{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"source": "https://lilianweng.github.io/posts/2023-06-23-agent/", "title": "LLM Powered Autonomous Agents | Lil'Log", "description": "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent\u2019s brain, complemented by several key components:", "language": "en", "source_url": "https://lilianweng.github.io/posts/2023-06-23-agent/", "type": "chunk", "doc_id": "eb401951-0339-4b4d-b781-be6caa63f8c6", "original_doc_id": "c6648d8a-a50c-4f1f-94c6-e323487d2168"}, "page_content": "pytest\ndataclasses\n\n\nConversatin samples:\n[\n  {\n    \"role\": \"system\",\n    \"content\": \"You will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\n\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\n\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code's language, and CODE is the code:\\n\\nFILENAME\\n```LANG\\nCODE\\n```\\n\\nYou will start with the \\\"entrypoint\\\" file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\n\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\n\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\n\\n\\nPython toolbelt preferences:\\n- pytest\\n- dataclasses\\n\"\n  },\n #  \u2026 same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\n  {\n    \"role\": \"assistant\",\n    \"content\": \"Assumptions:\\n1. Model: The model will contain the game's data, such as level information, character states, and enemy positions.\\n2. View: The view will handle the game's visuals, including rendering the game objects, backgrounds, and updating the display.\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\n\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\n  },\n  {\n    \"role\": \"user\",\n    \"content\": \"Please now remember the steps:\\n\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\n\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code's language, and CODE is the code:\\n\\nFILENAME\\n```LANG\\nCODE\\n```\\n\\nPlease note that the code should be fully functional. No placeholders.\\n\\nYou will start with the \\\"entrypoint\\\" file, then go to the ones that are imported by that file, and so on.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\n\"\n  }\n]\nChallenges#\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\n\n\nFinite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\n\n\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\n\n\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\n\n\nCitation#\nCited as:\n\nWeng, Lilian. (Jun 2023). \u201cLLM-powered Autonomous Agents\u201d. Lil\u2019Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\n\nOr\n@article{weng2023agent,\n  title   = \"LLM-powered Autonomous Agents\",\n  author  = \"Weng, Lilian\",\n  journal = \"lilianweng.github.io\",\n  year    = \"2023\",\n  month   = \"Jun\",\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\n}\nReferences#\n[1] Wei et al. \u201cChain of thought prompting elicits reasoning in large language models.\u201d NeurIPS 2022\n[2] Yao et al. \u201cTree of Thoughts: Dliberate Problem Solving with Large Language Models.\u201d arXiv preprint arXiv:2305.10601 (2023).\n[3] Liu et al. \u201cChain of Hindsight Aligns Language Models with Feedback\n\u201c arXiv preprint arXiv:2302.02676 (2023).\n[4] Liu et al. \u201cLLM+P: Empowering Large Language Models with Optimal Planning Proficiency\u201d arXiv preprint arXiv:2304.11477 (2023).\n[5] Yao et al. \u201cReAct: Synergizing reasoning and acting in language models.\u201d ICLR 2023.\n[6] Google Blog. \u201cAnnouncing ScaNN: Efficient Vector Similarity Search\u201d July 28, 2020.\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\n[8] Shinn & Labash. \u201cReflexion: an autonomous agent with dynamic memory and self-reflection\u201d arXiv preprint arXiv:2303.11366 (2023).\n[9] Laskin et al. \u201cIn-context Reinforcement Learning with Algorithm Distillation\u201d ICLR 2023.\n[10] Karpas et al. \u201cMRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.\u201d arXiv preprint arXiv:2205.00445 (2022).\n[11] Nakano et al. \u201cWebgpt: Browser-assisted question-answering with human feedback.\u201d arXiv preprint arXiv:2112.09332 (2021).\n[12] Parisi et al. \u201cTALM: Tool Augmented Language Models\u201d\n[13] Schick et al. \u201cToolformer: Language Models Can Teach Themselves to Use Tools.\u201d arXiv preprint arXiv:2302.04761 (2023).\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\n[15] Li et al. \u201cAPI-Bank: A Benchmark for Tool-Augmented LLMs\u201d arXiv preprint arXiv:2304.08244 (2023).\n[16] Shen et al. \u201cHuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace\u201d arXiv preprint arXiv:2303.17580 (2023).\n[17] Bran et al. \u201cChemCrow: Augmenting large-language models with chemistry tools.\u201d arXiv preprint arXiv:2304.05376 (2023).\n[18] Boiko et al. \u201cEmergent autonomous scientific research capabilities of large language models.\u201d arXiv preprint arXiv:2304.05332 (2023).\n[19] Joon Sung Park, et al. \u201cGenerative Agents: Interactive Simulacra of Human Behavior.\u201d arXiv preprint arXiv:2304.03442 (2023).\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\n\n\n\nnlp\nlanguage-model\nagent\nsteerability\nprompting\n\n\n\n\u00ab \n\nAdversarial Attacks on LLMs\n\n\n \u00bb\n\nPrompt Engineering\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a9 2024 Lil'Log\n\n        Powered by\n        Hugo &\n        PaperMod", "type": "Document"}}